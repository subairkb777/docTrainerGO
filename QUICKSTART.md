# ğŸš€ Quick Start Guide

Get DocTrainerGO up and running in 5 minutes!

## Prerequisites

- **Go 1.21+** â†’ [Download](https://go.dev/dl/)
- **Ollama** â†’ [Download](https://ollama.com/) (optional, for chat)

## Installation

### Option 1: Automated Setup (Recommended)

```bash
# Navigate to project directory
cd docTrainerGO

# Run setup script
./setup.sh

# Or use Makefile
make setup
```

### Option 2: Manual Setup

```bash
# 1. Download Go dependencies
go mod download

# 2. Download Fuse.js
curl -L https://cdn.jsdelivr.net/npm/fuse.js@6.6.2/dist/fuse.min.js -o static/fuse.min.js

# 3. Verify installation
./verify.sh
```

## Usage

### Step 1: Prepare PDF

```bash
# Copy your PDF to input directory
cp ~/Documents/manual.pdf input/
```

### Step 2: Process PDF

```bash
# Option A: Using Makefile (recommended)
make process PDF=input/manual.pdf

# Option B: Using go run
go run cmd/main.go -pdf=input/manual.pdf
```

**Output:**
```
Processing PDF: input/manual.pdf
â†’ Parsing PDF and extracting content...
  Found 12 sections
â†’ Generating HTML pages...
Generated: docs/index.html
â†’ Creating search index...
âœ“ PDF processing complete!
```

### Step 3: Start Ollama (Optional)

Open a **new terminal** and run:

```bash
# Download model (first time only)
ollama pull llama3.1

# Start Ollama
ollama run llama3.1
```

Keep this terminal open while using the chat feature.

### Step 4: Start Web Server

Back in your main terminal:

```bash
# Option A: Using Makefile
make serve

# Option B: Using go run
go run cmd/main.go -serve

# Option C: Custom port
make serve PORT=3000
```

**Output:**
```
âœ“ Connected to Ollama
ğŸš€ Server running at http://localhost:8080
   Press Ctrl+C to stop
```

### Step 5: Open Browser

Visit: **http://localhost:8080**

You should see:
- âœ… Your PDF content as a beautiful website
- âœ… Searchable documentation
- âœ… Sidebar navigation
- âœ… AI chat assistant (bottom-right)

## Common Commands

```bash
# Verify project structure
./verify.sh

# Process PDF
make process PDF=input/document.pdf

# Serve with custom port
make serve PORT=3000

# Build binary
make build
./doctrainer -serve

# Clean generated files
make clean

# View all commands
make help
```

## Troubleshooting

### "Go not found"
```bash
# Install Go from: https://go.dev/dl/
# Then verify:
go version
```

### "Ollama not accessible"
```bash
# Check if Ollama is running:
ps aux | grep ollama

# Start Ollama:
ollama serve

# In another terminal:
ollama run llama3.1
```

### "Search not working"
```bash
# Download Fuse.js:
make download-fuse

# Or manually:
curl -L https://cdn.jsdelivr.net/npm/fuse.js@6.6.2/dist/fuse.min.js -o static/fuse.min.js
```

### "Port already in use"
```bash
# Use different port:
make serve PORT=3000

# Or kill process on port 8080:
lsof -ti:8080 | xargs kill
```

## Next Steps

- ğŸ“– Read the full [README.md](README.md)
- ğŸ’¡ Check [EXAMPLES.md](EXAMPLES.md) for advanced usage
- ğŸ¨ Customize `static/style.css` for your branding
- ğŸ”§ Modify `templates/page.html` for layout changes

## Architecture Overview

```
PDF File (input/)
    â†“
Go Parser (internal/pdf/)
    â†“ extracts
Text + Images
    â†“
HTML Generator (internal/generator/)
    â†“ creates
Static Website (docs/)
    â†“
Web Server (cmd/main.go)
    â†“ serves
Browser â† â†’ Chat API â†’ Ollama LLM
```

## File Structure

```
docTrainerGO/
â”œâ”€â”€ input/           # Place PDFs here
â”œâ”€â”€ docs/            # Generated website (auto-created)
â”œâ”€â”€ static/          # CSS, JS, libraries
â”œâ”€â”€ templates/       # HTML templates
â”œâ”€â”€ internal/        # Go packages
â”‚   â”œâ”€â”€ pdf/        # PDF parsing
â”‚   â”œâ”€â”€ generator/  # HTML generation
â”‚   â”œâ”€â”€ search/     # Search index
â”‚   â””â”€â”€ chat/       # Ollama integration
â””â”€â”€ cmd/            # Main application
```

## Tips

1. **Large PDFs**: Processing may take 1-2 minutes for files >50MB
2. **Images**: Extracted images are saved in `docs/images/`
3. **Search**: Press `Ctrl+K` (or `Cmd+K` on Mac) to focus search
4. **Chat**: Works best with llama3.1, mistral, or codellama models
5. **Offline**: Everything runs locally, no internet required after setup

## Support

- ğŸ› Found a bug? Check browser console and server logs
- ğŸ’¬ Need help? Open an issue on GitHub
- ğŸ“§ Questions? Read the full README.md

---

**Ready to go!** ğŸ‰

Run `./setup.sh` to begin, or `make help` for all commands.
